{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import sklearn.neighbors\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pandas as pd \n",
    "import skimage\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset paths and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_id = 2\n",
    "im, data = load_sample(image_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linetypes\n",
    "def draw_pipelines(image, data=data):\n",
    "    draw = image.copy()\n",
    "    solid_lines = np.stack(data[\"lines\"].query(\"type=='solid'\")[\"box\"])\n",
    "    dashed_lines = np.stack(data[\"lines\"].query(\"type=='dashed'\")[\"box\"])\n",
    "\n",
    "    draw = cv2.drawContours(draw, solid_lines.reshape(-1,2,2), -1, (255, 255, 0), thickness=2)\n",
    "    draw = cv2.drawContours(draw, dashed_lines.reshape(-1,2,2), -1, (0, 255, 255), thickness=2)\n",
    "    return draw\n",
    "\n",
    "def draw_detections(image, rects, classes,color=(255,0,0)):\n",
    "    draw_rects(image, rects, thickness=8, color=color)\n",
    "    for r,c in zip(rects,classes):\n",
    "        cv2.putText(image, str(c), r.flatten()[:2], cv2.FONT_HERSHEY_PLAIN, 4, (0,0,0))\n",
    "\n",
    "def draw_symbols(image, data=data, color=None, thickness=2):\n",
    "    draw = image.copy()\n",
    "    for i, group in data[\"symbols\"].groupby(\"class\"):\n",
    "        color_ = color or (np.random.rand(3)*255).astype(np.uint8)\n",
    "        symbols = np.stack(group[\"box\"])\n",
    "        draw_rects(draw, symbols, color=[int(c) for c in color_], thickness=thickness)\n",
    "    return draw\n",
    "\n",
    "def draw_gt_symbols(image, data=data,color=None, thickness=2):\n",
    "    symbol_boxes = np.stack(data[\"symbols\"][\"box\"])\n",
    "    symbol_classes = np.stack(data[\"symbols\"][\"class\"]).astype(int)\n",
    "    draw_detections(image, symbol_boxes, symbol_classes, color=color)\n",
    "\n",
    "def draw_text_boxes(image, data=data, color=(255,0,255), thickness=1):\n",
    "    draw = image.copy()\n",
    "    text_boxes = np.stack(data[\"words\"][\"box\"])\n",
    "    draw_rects(draw, text_boxes, color=color, thickness=thickness)\n",
    "    return draw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f17e1fbe310>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "\n",
    "# im = cv2.imread(\"test.jpg\")\n",
    "draw = im.copy()\n",
    "draw = draw_pipelines(draw)\n",
    "draw = draw_symbols(draw)\n",
    "draw = draw_text_boxes(draw)\n",
    "plt.imshow(draw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection with blackhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_symbols(image):\n",
    "\n",
    "    if image.ndim == 3:\n",
    "        gray = np.mean(image,axis=-1).astype(np.uint8)\n",
    "    else:\n",
    "        gray=image\n",
    "\n",
    "    t, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "    # Foreground is smaller than 50% of image\n",
    "    if np.count_nonzero(thresh) > thresh.size/2:\n",
    "        thresh = 255-thresh\n",
    "\n",
    "    skel = skimage.morphology.skeletonize(thresh//255, method=\"lee\")\n",
    "\n",
    "    kern = cv2.getStructuringElement(cv2.MORPH_RECT, ksize=(35,35))\n",
    "    closing_kern = cv2.getStructuringElement(cv2.MORPH_RECT, ksize=(5,5))\n",
    "\n",
    "    blackhat = cv2.morphologyEx(skel, cv2.MORPH_BLACKHAT, kern)\n",
    "\n",
    "    blackhat = cv2.morphologyEx(blackhat, cv2.MORPH_OPEN, closing_kern)\n",
    "    blackhat = cv2.morphologyEx(blackhat, cv2.MORPH_CLOSE, closing_kern, iterations=3)\n",
    "\n",
    "    blackhat = cv2.morphologyEx(blackhat, cv2.MORPH_DILATE, closing_kern, iterations=2)\n",
    "    blackhat = cv2.morphologyEx(blackhat, cv2.MORPH_ERODE, closing_kern, iterations=1)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(blackhat*255, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    symbol_boxes = []\n",
    "    for c in contours:\n",
    "        if cv2.contourArea(c) > 10:\n",
    "            x,y,w,h =cv2.boundingRect(c)\n",
    "            symbol_boxes.append([x,y,x+w,y+h])\n",
    "\n",
    "    boxes = np.stack(symbol_boxes)\n",
    "    return non_max_suppression_fast(boxes,overlapThresh=0.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_symbols_2(image):\n",
    "    if image.ndim == 3:\n",
    "        gray = np.mean(image,axis=-1).astype(np.uint8)\n",
    "    else:\n",
    "        gray=image\n",
    "\n",
    "    t, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "    # Foreground is smaller than 50% of image\n",
    "    if np.count_nonzero(thresh) > thresh.size/2:\n",
    "        thresh = 255-thresh\n",
    "\n",
    "    skel = skimage.morphology.skeletonize(thresh//255, method=\"lee\")\n",
    "\n",
    "    vkern = cv2.getStructuringElement(cv2.MORPH_RECT, ksize=(1,35))\n",
    "    hkern = cv2.getStructuringElement(cv2.MORPH_RECT, ksize=(35,1))\n",
    "    closing_kern = cv2.getStructuringElement(cv2.MORPH_RECT, ksize=(3,3))\n",
    "    # kern = cv2.getStructuringElement(cv2.MORPH_RECT, ksize=(5,5))\n",
    "\n",
    "    # blackhat = cv2.morphologyEx(skel, cv2.MORPH_DILATE, closing_kern)\n",
    "    blackhat=skel\n",
    "\n",
    "    verod = cv2.morphologyEx(blackhat, cv2.MORPH_ERODE, vkern)\n",
    "    herod = cv2.morphologyEx(blackhat, cv2.MORPH_ERODE, hkern)\n",
    "\n",
    "    blackhat = verod | herod\n",
    "\n",
    "    blackhat = skel - blackhat\n",
    "\n",
    "    blackhat = cv2.morphologyEx(blackhat, cv2.MORPH_DILATE, closing_kern)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(blackhat*255, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    symbol_boxes = []\n",
    "    for c in contours:\n",
    "        if cv2.contourArea(c) > 150:\n",
    "            x,y,w,h =cv2.boundingRect(c)\n",
    "            symbol_boxes.append([x,y,x+w,y+h])\n",
    "\n",
    "    boxes = np.stack(symbol_boxes)\n",
    "    return non_max_suppression_fast(boxes,overlapThresh=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect without text removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fabbdc3ff10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,2, sharex=True, sharey=True)\n",
    "\n",
    "draw = im.copy()\n",
    "\n",
    "symbol_boxes = detect_symbols(im)\n",
    "\n",
    "draw_rects(draw, np.stack(symbol_boxes).reshape(-1,2,2), thickness=8)\n",
    "axs[0].imshow(draw)\n",
    "\n",
    "draw2 = draw_symbols(draw, thickness=8, color=(0,255,0))\n",
    "axs[1].imshow(draw2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect with text removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/freitas/Code/CMP-197/pid_detection/notebook/detection.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/freitas/Code/CMP-197/pid_detection/notebook/detection.ipynb#ch0000013?line=0'>1</a>\u001b[0m fig, axs \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m, sharex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, sharey\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/freitas/Code/CMP-197/pid_detection/notebook/detection.ipynb#ch0000013?line=2'>3</a>\u001b[0m \u001b[39m# Pre-process\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/freitas/Code/CMP-197/pid_detection/notebook/detection.ipynb#ch0000013?line=3'>4</a>\u001b[0m im_cleanup \u001b[39m=\u001b[39m cleanup_text(im, img_id\u001b[39m=\u001b[39;49mimage_id)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/freitas/Code/CMP-197/pid_detection/notebook/detection.ipynb#ch0000013?line=4'>5</a>\u001b[0m draw \u001b[39m=\u001b[39m im_cleanup\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/freitas/Code/CMP-197/pid_detection/notebook/detection.ipynb#ch0000013?line=6'>7</a>\u001b[0m \u001b[39m# Detect\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/CMP-197/pid_detection/notebook/common.py:178\u001b[0m, in \u001b[0;36mcleanup_text\u001b[0;34m(im, img_id)\u001b[0m\n\u001b[1;32m    <a href='file:///home/freitas/Code/CMP-197/pid_detection/notebook/common.py?line=175'>176</a>\u001b[0m outputs \u001b[39m=\u001b[39m []\n\u001b[1;32m    <a href='file:///home/freitas/Code/CMP-197/pid_detection/notebook/common.py?line=176'>177</a>\u001b[0m \u001b[39mfor\u001b[39;00m window \u001b[39min\u001b[39;00m t\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39mint\u001b[39m(wh),\u001b[39mint\u001b[39m(ww)):\n\u001b[0;32m--> <a href='file:///home/freitas/Code/CMP-197/pid_detection/notebook/common.py?line=177'>178</a>\u001b[0m     prediction_result \u001b[39m=\u001b[39m get_prediction(\n\u001b[1;32m    <a href='file:///home/freitas/Code/CMP-197/pid_detection/notebook/common.py?line=178'>179</a>\u001b[0m         image\u001b[39m=\u001b[39;49mwindow,\n\u001b[1;32m    <a href='file:///home/freitas/Code/CMP-197/pid_detection/notebook/common.py?line=179'>180</a>\u001b[0m         craft_net\u001b[39m=\u001b[39;49mcraft_net,\n\u001b[1;32m    <a href='file:///home/freitas/Code/CMP-197/pid_detection/notebook/common.py?line=180'>181</a>\u001b[0m         refine_net\u001b[39m=\u001b[39;49mrefine_net,\n\u001b[1;32m    <a href='file:///home/freitas/Code/CMP-197/pid_detection/notebook/common.py?line=181'>182</a>\u001b[0m         cuda\u001b[39m=\u001b[39;49mUSE_CUDA,\n\u001b[1;32m    <a href='file:///home/freitas/Code/CMP-197/pid_detection/notebook/common.py?line=182'>183</a>\u001b[0m         poly\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///home/freitas/Code/CMP-197/pid_detection/notebook/common.py?line=183'>184</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/freitas/Code/CMP-197/pid_detection/notebook/common.py?line=184'>185</a>\u001b[0m     outputs\u001b[39m.\u001b[39mappend(prediction_result)\n\u001b[1;32m    <a href='file:///home/freitas/Code/CMP-197/pid_detection/notebook/common.py?line=186'>187</a>\u001b[0m \u001b[39m# Offset the predictions back into the original (full) image\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/predict.py:68\u001b[0m, in \u001b[0;36mget_prediction\u001b[0;34m(image, craft_net, refine_net, text_threshold, link_threshold, low_text, cuda, long_size, poly)\u001b[0m\n\u001b[1;32m     <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/predict.py?line=65'>66</a>\u001b[0m \u001b[39m# forward pass\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/predict.py?line=66'>67</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch_utils\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/predict.py?line=67'>68</a>\u001b[0m     y, feature \u001b[39m=\u001b[39m craft_net(x)\n\u001b[1;32m     <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/predict.py?line=68'>69</a>\u001b[0m craftnet_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t0\n\u001b[1;32m     <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/predict.py?line=69'>70</a>\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/models/craftnet.py:81\u001b[0m, in \u001b[0;36mCraftNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/models/craftnet.py?line=76'>77</a>\u001b[0m y \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39minterpolate(\n\u001b[1;32m     <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/models/craftnet.py?line=77'>78</a>\u001b[0m     y, size\u001b[39m=\u001b[39msources[\u001b[39m3\u001b[39m]\u001b[39m.\u001b[39msize()[\u001b[39m2\u001b[39m:], mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbilinear\u001b[39m\u001b[39m\"\u001b[39m, align_corners\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/models/craftnet.py?line=78'>79</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/models/craftnet.py?line=79'>80</a>\u001b[0m y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([y, sources[\u001b[39m3\u001b[39m]], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/models/craftnet.py?line=80'>81</a>\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupconv3(y)\n\u001b[1;32m     <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/models/craftnet.py?line=82'>83</a>\u001b[0m y \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39minterpolate(\n\u001b[1;32m     <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/models/craftnet.py?line=83'>84</a>\u001b[0m     y, size\u001b[39m=\u001b[39msources[\u001b[39m4\u001b[39m]\u001b[39m.\u001b[39msize()[\u001b[39m2\u001b[39m:], mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbilinear\u001b[39m\u001b[39m\"\u001b[39m, align_corners\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/models/craftnet.py?line=84'>85</a>\u001b[0m )\n\u001b[1;32m     <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/models/craftnet.py?line=85'>86</a>\u001b[0m y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([y, sources[\u001b[39m4\u001b[39m]], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/models/craftnet.py:27\u001b[0m, in \u001b[0;36mdouble_conv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/models/craftnet.py?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/models/craftnet.py?line=26'>27</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x)\n\u001b[1;32m     <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/craft_text_detector/models/craftnet.py?line=27'>28</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=445'>446</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=446'>447</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=438'>439</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=439'>440</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=440'>441</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=441'>442</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=442'>443</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    <a href='file:///home/freitas/Code/CMP-197/pid_detection/.venv/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=443'>444</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,2, sharex=True, sharey=True)\n",
    "\n",
    "# Pre-process\n",
    "im_cleanup = cleanup_text(im, img_id=image_id)\n",
    "draw = im_cleanup.copy()\n",
    "\n",
    "# Detect\n",
    "symbol_boxes = detect_symbols(im_cleanup)\n",
    "\n",
    "# Draw results\n",
    "draw_rects(draw, np.stack(symbol_boxes).reshape(-1,2,2), thickness=8)\n",
    "axs[0].imshow(draw)\n",
    "draw2 = draw_symbols(draw, thickness=8, color=(0,255,0))\n",
    "axs[1].imshow(draw2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect with gt text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f17e1f03940>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = im.copy()\n",
    "\n",
    "clean = draw_text_boxes(clean, color=(255,255,255), thickness=-1)\n",
    "plt.imshow(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=0.5197368421052632\n",
      "recall=0.7117117117117117\n"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,2, sharex=True, sharey=True)\n",
    "\n",
    "# Pre-process\n",
    "im_cleanup = clean\n",
    "draw = im_cleanup.copy()\n",
    "\n",
    "# Detect\n",
    "symbol_boxes = detect_symbols(im_cleanup)\n",
    "\n",
    "# Draw results\n",
    "draw_rects(draw, np.stack(symbol_boxes).reshape(-1,2,2), thickness=8)\n",
    "axs[0].imshow(draw)\n",
    "axs[0].set_title(\"Predicted\")\n",
    "axs[0].axis(\"off\")\n",
    "draw2 = draw_symbols(draw, thickness=8, color=(0,255,0))\n",
    "axs[1].imshow(draw2)\n",
    "axs[1].set_title(\"+Ground truth\")\n",
    "axs[1].axis(\"off\")\n",
    "\n",
    "precision, recall = detection_metrics(symbol_boxes, np.stack(data[\"symbols\"].box))\n",
    "\n",
    "print(f\"{precision=}\\n{recall=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision=0.6229508196721312\n",
      "recall=0.6846846846846847\n"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,2, sharex=True, sharey=True)\n",
    "\n",
    "# Pre-process\n",
    "im_cleanup = clean\n",
    "draw = im_cleanup.copy()\n",
    "\n",
    "# Detect\n",
    "symbol_boxes = detect_symbols_2(im_cleanup)\n",
    "\n",
    "# Draw results\n",
    "draw_rects(draw, np.stack(symbol_boxes).reshape(-1,2,2), thickness=8)\n",
    "axs[0].imshow(draw)\n",
    "draw2 = draw_symbols(draw, thickness=8, color=(0,255,0))\n",
    "axs[1].imshow(draw2)\n",
    "\n",
    "precision, recall = detection_metrics(symbol_boxes, np.stack(data[\"symbols\"].box))\n",
    "\n",
    "print(f\"{precision=}\\n{recall=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classsification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features for each object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mahotas \n",
    "\n",
    "def get_largest_contour(im):\n",
    "    contours, hierarchy = cv2.findContours(im, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cmax = sorted(contours, key=cv2.contourArea)[-1]\n",
    "    return cmax\n",
    "\n",
    "def zernike_adaptive_centroid(image, degree=8):\n",
    "    c = get_largest_contour(image)\n",
    "    (x,y),r = cv2.minEnclosingCircle(c)\n",
    "    return  mahotas.features.zernike_moments(image, r, degree=degree)\n",
    "\n",
    "def rect_to_slice(rect_pts, margin=0):\n",
    "    \"\"\"\n",
    "    Convert cv-style rect to numpy-style slice\n",
    "    \"\"\"\n",
    "    (x0, y0), (x1, y1) = rect_pts\n",
    "\n",
    "    return (slice(y0-margin, y1+margin), slice(x0-margin, x1+margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_square_thresh(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    t, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)\n",
    "\n",
    "    return resizeAndPad(thresh, (64,64), padColor=0)\n",
    "\n",
    "def get_zernike_features(image):\n",
    "    thresh = get_square_thresh(image)\n",
    "    return zernike_adaptive_centroid(thresh)\n",
    "\n",
    "crops = [ im_cleanup[rect_to_slice(s.reshape(2,2), margin=15)] for s in symbol_boxes] \n",
    "features = [ get_zernike_features(crop) for crop in crops]\n",
    "\n",
    "print(np.stack(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cluster\n",
    "\n",
    "centroid, labels, _ = sklearn.cluster.k_means(np.stack(features), n_clusters=5)\n",
    "# b = sklearn.cluster.estimate_bandwidth(np.stack(features))\n",
    "# centroid, labels = sklearn.cluster.mean_shift(np.stack(features), bandwidth=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in np.unique(labels):\n",
    "    fig,ax = plt.subplots(1, 1+np.count_nonzero(labels==l))\n",
    "    i=0\n",
    "    for label, crop in zip(labels,crops):\n",
    "        if label==l:\n",
    "            ax[i].imshow(crop)\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def load_training_set(feature_func):\n",
    "    training_img_ids = range(400,500) \n",
    "    templates_path = Path(\"../templates\")\n",
    "\n",
    "    file_pattern = re.compile(r\"im(\\d+)_sym(\\d+)\")\n",
    "\n",
    "    train_x = []\n",
    "    train_y = []\n",
    "    for template in templates_path.glob(\"**/*.png\"):\n",
    "        file = template.stem\n",
    "        id, sym = file_pattern.match(file).groups() \n",
    "\n",
    "        if int(id) in training_img_ids:\n",
    "            template_im = cv2.imread(str(template))\n",
    "\n",
    "            # Features\n",
    "            train_x.append(feature_func(template_im))\n",
    "            # Folder is the class\n",
    "            train_y.append(int(template.parent.stem))\n",
    "\n",
    "    return np.stack(train_x), np.stack(train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_results(image, boxes, feature_func, class_pipeline):\n",
    "    fig, axs = plt.subplots(1,2, sharex=True, sharey=True)\n",
    "\n",
    "    draw = image.copy()\n",
    "\n",
    "    # Detect\n",
    "    # symbol_boxes = detect_symbols(im_cleanup)\n",
    "    # symbol_boxes = np.stack(data[\"symbols\"][\"box\"])\n",
    "    crops = [ image[rect_to_slice(s.reshape(2,2), margin=15)] for s in boxes] \n",
    "    features = [ feature_func(crop) for crop in crops]\n",
    "\n",
    "    probas = class_pipeline.predict_proba(features)\n",
    "    predictions = 1+np.argmax(probas,axis=1)\n",
    "    confidences = np.max(probas,axis=1)\n",
    "\n",
    "    draw_gt_symbols(draw2, thickness=8, color=(0,255,0))\n",
    "    axs[0].imshow(draw2)\n",
    "\n",
    "    # Draw results\n",
    "    draw_detections(draw, np.stack(boxes).reshape(-1,2,2), predictions)\n",
    "    axs[1].imshow(draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('classifier', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"classifier\", sklearn.neighbors.KNeighborsClassifier(n_neighbors=5))])\n",
    "\n",
    "train_x, train_y = load_training_set(feature_func=get_zernike_features)\n",
    "pipe.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results(image=im_cleanup, \n",
    "             boxes=detect_symbols(im_cleanup),\n",
    "             feature_func=get_zernike_features,\n",
    "             class_pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('classifier', KNeighborsClassifier(metric='hamming'))])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([(\"classifier\", sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, metric=\"hamming\"),)])\n",
    "\n",
    "ham_features = lambda x: get_square_thresh(x).ravel()\n",
    "train_x, train_y = load_training_set(feature_func=ham_features)\n",
    "pipe.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results(image=im_cleanup, \n",
    "             boxes=detect_symbols(im_cleanup),\n",
    "             feature_func=ham_features,\n",
    "             class_pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(1,2, sharex=True, sharey=True)\n",
    "\n",
    "draw = im_cleanup.copy()\n",
    "\n",
    "# Detect\n",
    "# symbol_boxes = detect_symbols(im_cleanup)\n",
    "symbol_boxes = np.stack(data[\"symbols\"][\"box\"])\n",
    "predictions = np.stack(data[\"symbols\"][\"class\"]).astype(int)\n",
    "\n",
    "# Draw results\n",
    "draw_detections(draw, np.stack(symbol_boxes).reshape(-1,2,2), predictions)\n",
    "axs[0].imshow(draw)\n",
    "draw2 = draw_symbols(draw, thickness=8, color=(0,255,0))\n",
    "axs[1].imshow(draw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapcalc import calculate_map, calculate_map_range\n",
    "\n",
    "\n",
    "gt_boxes = np.stack(data[\"symbols\"][\"box\"])\n",
    "gt_classes = np.stack(data[\"symbols\"][\"class\"]).astype(int)\n",
    "ground_truth_info={\"boxes\":gt_boxes,\"labels\":gt_classes}\n",
    "pred_info={\"boxes\":symbol_boxes,\"labels\":predictions}#, \"scores\":confidences}\n",
    "\n",
    "# calculate_map_range(ground_truth, predictions, 0.5,0.95,0.05)\n",
    "calculate_map(ground_truth_info, pred_info, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9bdb36c0916cc2b5bb5120fd2f5f8f06c9f98738dae7640ccf43c5ae0d8cee13"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
