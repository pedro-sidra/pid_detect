{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pandas as pd \n",
    "import skimage\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset paths and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbpath = Path(\"../DigitizePID_Dataset\")\n",
    "\n",
    "imagepath = dbpath /  \"image_2\"\n",
    "imageformat = \"jpg\"\n",
    "maskpath  = dbpath /  \"mask\"\n",
    "maskformat = \"png\"\n",
    "\n",
    "def im2mask(image):\n",
    "    return maskpath / f\"{image.stem}_mask.{maskformat}\"\n",
    "def mask2im(mask):\n",
    "    return imagepath / f\"{mask.stem}.{imageformat}\"\n",
    "def im2info(image):\n",
    "    dfs = {  }\n",
    "    for file in  (dbpath / image.stem).glob(\"*.npy\"):\n",
    "        data = np.load(str(file), allow_pickle=True)\n",
    "        name = file.stem.split(\"_\")[-1]\n",
    "        dfs[name] = pd.DataFrame(data)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample(image_id):\n",
    "    image = imagepath / f\"{image_id}.{imageformat}\"\n",
    "    im = cv2.imread(str(image))\n",
    "\n",
    "    # 375, 250\n",
    "    # 5630, 4300\n",
    "    roi = (slice(250, 4300), slice(375, 5630))\n",
    "    im = im[roi]\n",
    "\n",
    "    tr = np.array([375,250])\n",
    "\n",
    "    data = im2info(image)\n",
    "\n",
    "    # Translate lines\n",
    "    lines = np.stack(data[\"lines\"][1]).reshape(-1,2,2) - tr\n",
    "    data[\"lines\"][1] = list(lines.reshape(-1,4))\n",
    "    data[\"lines\"].columns=[\"name\",\"box\",\"code\",\"type\"]\n",
    "\n",
    "    # Fix text boxes\n",
    "    text_boxes = np.stack(data[\"words\"].iloc[:,1]).reshape(-1,2,2) - tr\n",
    "    # Sort X and Y coords inside each rect\n",
    "    text_boxes = np.sort(text_boxes.reshape(-1,2,2),axis=1)\n",
    "    data[\"words\"][1] = list(text_boxes.reshape(-1,4))\n",
    "    data[\"words\"].columns=[\"name\",\"box\",\"code\",\"type\"]\n",
    "\n",
    "    # Translate symbols\n",
    "    symbols = np.stack(data[\"symbols\"].iloc[:,1]).reshape(-1,2,2) - tr\n",
    "    data[\"symbols\"][1]=list(symbols.reshape(-1,4))\n",
    "    data[\"symbols\"].columns=[\"name\",\"box\",\"class\"]\n",
    "\n",
    "    return im, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, data = load_sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rects(img, tl_br_points, color=(255,0,0), **kwargs):\n",
    "\n",
    "    if tl_br_points.ndim!=3:\n",
    "        tl_br_points = tl_br_points.reshape(-1,2,2)\n",
    "\n",
    "    for p1, p2 in tl_br_points:\n",
    "        cv2.rectangle(img, p1, p2, color=color, **kwargs)\n",
    "\n",
    "# Linetypes\n",
    "def draw_pipelines(image, data=data):\n",
    "    draw = image.copy()\n",
    "    solid_lines = np.stack(data[\"lines\"].query(\"type=='solid'\")[\"box\"])\n",
    "    dashed_lines = np.stack(data[\"lines\"].query(\"type=='dashed'\")[\"box\"])\n",
    "\n",
    "    draw = cv2.drawContours(draw, solid_lines.reshape(-1,2,2), -1, (255, 255, 0), thickness=2)\n",
    "    draw = cv2.drawContours(draw, dashed_lines.reshape(-1,2,2), -1, (0, 255, 255), thickness=2)\n",
    "    return draw\n",
    "\n",
    "def draw_symbols(image, data=data, color=None, thickness=2):\n",
    "    draw = image.copy()\n",
    "    for i, group in data[\"symbols\"].groupby(\"class\"):\n",
    "        color_ = color or (np.random.rand(3)*255).astype(np.uint8)\n",
    "        symbols = np.stack(group[\"box\"])\n",
    "        draw_rects(draw, symbols, color=[int(c) for c in color_], thickness=thickness)\n",
    "    return draw\n",
    "\n",
    "def draw_text_boxes(image, data=data, color=(255,0,255), thickness=1):\n",
    "    draw = image.copy()\n",
    "    text_boxes = np.stack(data[\"words\"][\"box\"])\n",
    "    draw_rects(draw, text_boxes, color=color, thickness=thickness)\n",
    "    return draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efd434582b0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "\n",
    "# im = cv2.imread(\"test.jpg\")\n",
    "draw = im.copy()\n",
    "draw = draw_pipelines(draw)\n",
    "draw = draw_symbols(draw)\n",
    "draw = draw_text_boxes(draw)\n",
    "plt.imshow(draw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection with blackhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_symbols(image):\n",
    "\n",
    "    if image.ndim == 3:\n",
    "        gray = np.mean(image,axis=-1).astype(np.uint8)\n",
    "    else:\n",
    "        gray=image\n",
    "\n",
    "    t, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "    # Foreground is smaller than 50% of image\n",
    "    if np.count_nonzero(thresh) > thresh.size/2:\n",
    "        thresh = 255-thresh\n",
    "\n",
    "    skel = skimage.morphology.skeletonize(thresh//255, method=\"lee\")\n",
    "\n",
    "    kern = cv2.getStructuringElement(cv2.MORPH_RECT, ksize=(35,35))\n",
    "    closing_kern = cv2.getStructuringElement(cv2.MORPH_RECT, ksize=(5,5))\n",
    "\n",
    "    blackhat = cv2.morphologyEx(skel, cv2.MORPH_BLACKHAT, kern)\n",
    "\n",
    "    blackhat = cv2.morphologyEx(blackhat, cv2.MORPH_OPEN, closing_kern)\n",
    "    blackhat = cv2.morphologyEx(blackhat, cv2.MORPH_CLOSE, closing_kern, iterations=3)\n",
    "\n",
    "    blackhat = cv2.morphologyEx(blackhat, cv2.MORPH_DILATE, closing_kern, iterations=2)\n",
    "    blackhat = cv2.morphologyEx(blackhat, cv2.MORPH_ERODE, closing_kern, iterations=1)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(blackhat*255, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    symbol_boxes = []\n",
    "    for c in contours:\n",
    "        if cv2.contourArea(c) > 10:\n",
    "            x,y,w,h =cv2.boundingRect(c)\n",
    "            symbol_boxes.append([x,y,x+w,y+h])\n",
    "\n",
    "    return np.stack(symbol_boxes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect without text removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efd433f8e80>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,2, sharex=True, sharey=True)\n",
    "\n",
    "draw = im.copy()\n",
    "\n",
    "symbol_boxes = detect_symbols(im)\n",
    "\n",
    "draw_rects(draw, np.stack(symbol_boxes).reshape(-1,2,2), thickness=8)\n",
    "axs[0].imshow(draw)\n",
    "\n",
    "draw2 = draw_symbols(draw, thickness=8, color=(0,255,0))\n",
    "axs[1].imshow(draw2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features for each object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mahotas \n",
    "\n",
    "def get_largest_contour(im):\n",
    "    contours, hierarchy = cv2.findContours(im, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cmax = sorted(contours, key=cv2.contourArea)[-1]\n",
    "    return cmax\n",
    "\n",
    "def zernike_adaptive_centroid(image, degree=8):\n",
    "    c = get_largest_contour(image)\n",
    "    (x,y),r = cv2.minEnclosingCircle(c)\n",
    "    return  mahotas.features.zernike_moments(image, r, degree=degree)\n",
    "\n",
    "def rect_to_slice(rect_pts, margin=0):\n",
    "    \"\"\"\n",
    "    Convert cv-style rect to numpy-style slice\n",
    "    \"\"\"\n",
    "    (x0, y0), (x1, y1) = rect_pts\n",
    "\n",
    "    return (slice(y0-margin, y1+margin), slice(x0-margin, x1+margin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.18309886e-01 1.08796273e-01 2.92339949e-02 ... 9.55055909e-02\n",
      "  3.09650680e-02 3.90511023e-02]\n",
      " [3.18309886e-01 2.07845653e-04 2.25211249e-01 ... 8.30285786e-03\n",
      "  6.96331941e-02 2.54502277e-02]\n",
      " [3.18309886e-01 3.02747019e-03 1.50428320e-01 ... 2.26116712e-02\n",
      "  7.37736842e-03 5.94830356e-02]\n",
      " ...\n",
      " [3.18309886e-01 4.80393568e-05 2.76528224e-01 ... 7.11736848e-02\n",
      "  5.83531401e-03 7.60186801e-02]\n",
      " [3.18309886e-01 1.02862569e-02 1.81708813e-01 ... 2.53316930e-02\n",
      "  2.55687760e-02 4.00401239e-02]\n",
      " [3.18309886e-01 6.30387292e-04 2.06634989e-01 ... 4.01115882e-02\n",
      "  1.08528253e-02 5.94822683e-02]]\n"
     ]
    }
   ],
   "source": [
    "gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "t, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "crops = [ thresh[rect_to_slice(s.reshape(2,2), margin=15)] for s in symbol_boxes] \n",
    "\n",
    "features = [ zernike_adaptive_centroid(crop) for crop in crops]\n",
    "\n",
    "print(np.stack(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.cluster\n",
    "\n",
    "centroid, labels, _ = sklearn.cluster.k_means(np.stack(features), n_clusters=5)\n",
    "# b = sklearn.cluster.estimate_bandwidth(np.stack(features))\n",
    "# centroid, labels = sklearn.cluster.mean_shift(np.stack(features), bandwidth=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in np.unique(labels):\n",
    "    fig,ax = plt.subplots(1, 1+np.count_nonzero(labels==l))\n",
    "    i=0\n",
    "    for label, crop in zip(labels,crops):\n",
    "        if label==l:\n",
    "            ax[i].imshow(crop)\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9bdb36c0916cc2b5bb5120fd2f5f8f06c9f98738dae7640ccf43c5ae0d8cee13"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
